{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import cross_validation\n",
    "import lightfm.evaluation as lfm_eval\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of data used for testing\n",
    "TEST_PERCENTAGE = 0.2\n",
    "# model learning rate\n",
    "LEARNING_RATE = 0.25\n",
    "# no of latent factors\n",
    "NO_COMPONENTS = 30\n",
    "# no of epochs to fit model\n",
    "NO_EPOCHS = 30\n",
    "# no of threads to fit model\n",
    "NO_THREADS = 32\n",
    "# regularisation for both user and item features\n",
    "ITEM_ALPHA = 1e-6\n",
    "USER_ALPHA = 1e-6\n",
    "\n",
    "# seed for pseudonumber generations\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/merged.csv',index_col=0)\n",
    "data = pd.read_csv('../data/interim/data.csv',index_col=0)\n",
    "items = pd.read_csv('../data/interim/items.csv',index_col=0)\n",
    "users = pd.read_csv('../data/interim/users.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = list(df.columns[8:-4])\n",
    "occupations = df['occupation'].unique().tolist()\n",
    "user_features_names = ['age','gender', *occupations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.fit(df['user_id'], df['item_id'],user_features=user_features_names, item_features=genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = dataset.build_item_features((x,y[1].to_dict()) for x,y in zip(items['item_id'], items[items.columns[5:]].iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_user_features():\n",
    "    for i, row in users.iterrows():\n",
    "        features_map = {x:0 for x in occupations}\n",
    "        user_id = row['user_id']\n",
    "        features_map[row['occupation']] = 1\n",
    "        features_map['age'] = row['age']\n",
    "        features_map['gender'] = 1 if row['gender'] == 'M' else 0\n",
    "        yield user_id, features_map\n",
    "\n",
    "user_features = dataset.build_user_features(retrieve_user_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions, weights = dataset.build_interactions(data.iloc[:, :3].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions, test_interactions = cross_validation.random_train_test_split(interactions,TEST_PERCENTAGE,random_state=np.random.RandomState(SEED))\n",
    "train_weights, test_weights = cross_validation.random_train_test_split(weights,TEST_PERCENTAGE,random_state=np.random.RandomState(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(loss='warp', no_components=NO_COMPONENTS, \n",
    "                 learning_rate=LEARNING_RATE, \n",
    "                 item_alpha=ITEM_ALPHA,\n",
    "                 user_alpha=USER_ALPHA,\n",
    "                 random_state=np.random.RandomState(SEED)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 30/30 [00:51<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "fitted_model = model.fit(interactions=train_interactions,\n",
    "           user_features=user_features,\n",
    "           item_features=item_features,\n",
    "           sample_weight=train_weights,\n",
    "           epochs=NO_EPOCHS,\n",
    "           verbose=True,\n",
    "           num_threads=NO_THREADS\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../models/lfm_1.pkl', 'wb') as outp: \n",
    "    pickle.dump(fitted_model, outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../benchmark/data/benchmark_data.pkl', 'wb') as outp: \n",
    "    bench_data = {\n",
    "        'test_interactions': test_interactions,\n",
    "        'train_interactions': train_interactions,\n",
    "        'user_features': user_features,\n",
    "        'item_features': item_features\n",
    "    }\n",
    "    pickle.dump(bench_data, outp)\n",
    "\n",
    "with open('../src/data/dataset_internal.pkl', 'wb') as outp: \n",
    "    pickle.dump(dataset,outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train auc: 0.94\n",
      "Test auc: 0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"Train auc: %.2f\" % lfm_eval.auc_score(fitted_model, train_interactions,item_features=item_features,user_features=user_features).mean())\n",
    "print(\"Test auc: %.2f\" % lfm_eval.auc_score(fitted_model, test_interactions, train_interactions=train_interactions,item_features=item_features,user_features=user_features).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision@10: 0.61\n",
      "Test precision@10: 0.33\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "print(f\"Train precision@{k}: %.2f\" % lfm_eval.precision_at_k(fitted_model, train_interactions, k=k,item_features=item_features,user_features=user_features).mean())\n",
    "print(f\"Test precision@{k}: %.2f\" % lfm_eval.precision_at_k(fitted_model, test_interactions, train_interactions=train_interactions, k=k,item_features=item_features,user_features=user_features).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall@10: 0.12\n",
      "Test recall@10: 0.20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train recall@{k}: %.2f\" % lfm_eval.recall_at_k(fitted_model, train_interactions,k=k,item_features=item_features,user_features=user_features).mean())\n",
    "print(f\"Test recall@{k}: %.2f\" % lfm_eval.recall_at_k(fitted_model, test_interactions, k=k,train_interactions=train_interactions,item_features=item_features,user_features=user_features).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reciporial rank: 0.83\n",
      "Test reciporial rank: 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train reciporial rank: %.2f\" % lfm_eval.reciprocal_rank(fitted_model, train_interactions,item_features=item_features,user_features=user_features).mean())\n",
    "print(\"Test reciporial rank: %.2f\" % lfm_eval.reciprocal_rank(fitted_model, test_interactions, train_interactions=train_interactions,item_features=item_features,user_features=user_features).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_map, ufeature_map, iid_map, ifeature_map = dataset.mapping()\n",
    "\n",
    "iid_map_reversed = {v:k for k,v in iid_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation(model, user_ids, k=3):\n",
    "\n",
    "    n_users, n_items = dataset.interactions_shape()\n",
    "\n",
    "    user_ids_internal = [uid_map[user_id] for user_id in user_ids]\n",
    "\n",
    "    for user_id, user_id_internal in zip(user_ids, user_ids_internal):\n",
    "\n",
    "        scores = model.predict(user_id_internal, np.arange(n_items))\n",
    "        top_items_idxs_internal = np.argsort(-scores)\n",
    "        top_items_idxs = [iid_map_reversed[item_id] for item_id in top_items_idxs_internal]\n",
    "        top_items = [items[items['item_id'] == item_id]['title'].values[0] for item_id in top_items_idxs]\n",
    "\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Recommended:\")\n",
    "\n",
    "        for x in top_items[:k]:\n",
    "            print(\"        %s\" % x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "     Recommended:\n",
      "        Starship Troopers (1997)\n",
      "        Everyone Says I Love You (1996)\n",
      "        Devil's Own, The (1997)\n",
      "User 25\n",
      "     Recommended:\n",
      "        African Queen, The (1951)\n",
      "        2001: A Space Odyssey (1968)\n",
      "        Arsenic and Old Lace (1944)\n",
      "User 450\n",
      "     Recommended:\n",
      "        Batman (1989)\n",
      "        Ghost (1990)\n",
      "        Grease (1978)\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(fitted_model, [3, 25, 450])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml-rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
